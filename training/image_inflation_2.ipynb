{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_inflation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2qaT25ZiS-P",
        "colab_type": "text"
      },
      "source": [
        "## Setup Github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6Q3FPg4-bWw",
        "colab_type": "text"
      },
      "source": [
        "Import the github repository and move it into the local directory (also remove the defult samples directoy if it exists)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9pnfHbSqgXh",
        "colab_type": "code",
        "outputId": "37c7f16e-520f-4b2c-953b-d439f5c503d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "if not os.path.isdir(\".git\"):\n",
        "    user = \"jiaye-mao\"\n",
        "    password = getpass('github password')\n",
        "    os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "\n",
        "    # clone the repo\n",
        "    !git clone https://$GITHUB_AUTH@github.com/msc-acse/acse-8-miniproject-softmax.git repo\n",
        "\n",
        "    # move the repo up one\n",
        "    !mv repo/* .\n",
        "    !mv repo/.git .\n",
        "\n",
        "    # delete un needed stuff\n",
        "    !rm -r repo\n",
        "    !rm -r sample_data/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "github password··········\n",
            "Cloning into 'repo'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 721 (delta 19), reused 29 (delta 9), pack-reused 678\u001b[K\n",
            "Receiving objects: 100% (721/721), 204.94 MiB | 36.75 MiB/s, done.\n",
            "Resolving deltas: 100% (386/386), done.\n",
            "Checking out files: 100% (108/108), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taP042kg_fDc",
        "colab_type": "text"
      },
      "source": [
        "### Github Commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LinpUehg09_o",
        "colab_type": "code",
        "outputId": "a6ec1ef6-b7ac-44a0-f5ea-94fcc2fc1145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "!git checkout richard\n",
        "# !git reset --hard\n",
        "!git pull origin richard\n",
        "!ls -l\n",
        "!git log -1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D\t.gitignore\n",
            "Branch 'richard' set up to track remote branch 'richard' from 'origin'.\n",
            "Switched to a new branch 'richard'\n",
            "From https://github.com/msc-acse/acse-8-miniproject-softmax\n",
            " * branch            richard    -> FETCH_HEAD\n",
            "Already up to date.\n",
            "total 32\n",
            "drwxr-xr-x  2 root root  4096 May 23 15:59 data\n",
            "drwxr-xr-x 13 root root  4096 May 23 16:00 models\n",
            "-rw-r--r--  1 root root   771 May 23 15:59 README.md\n",
            "drwxr-xr-x  2 root root  4096 May 23 16:00 spec\n",
            "-rw-r--r--  1 root root 10208 May 23 15:59 tools.py\n",
            "drwxr-xr-x  3 root root  4096 May 23 16:00 training\n",
            "\u001b[33mcommit 3f0369b68a7f2437e6943031276a104cc8f59bd4\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mrichard\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/richard\u001b[m\u001b[33m)\u001b[m\n",
            "Author: Boyne272 <boynerichard@yahoo.co.uk>\n",
            "Date:   Thu May 23 11:49:24 2019 +0100\n",
            "\n",
            "    added my version of a larger nural network\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGLYFKY1CnP",
        "colab_type": "text"
      },
      "source": [
        "## Setup Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvJ4qN51_mPP",
        "colab_type": "text"
      },
      "source": [
        "Ipython imports and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdWZQ7cefhiI",
        "colab_type": "code",
        "outputId": "bd372ce0-770b-4ad9-b56b-ec7c13761dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1067
        }
      },
      "source": [
        "# ipython setup\n",
        "!pip install pycm livelossplot\n",
        "%pylab inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/86/14ebc41098fb81eb7e458d234622a9ce50857bb7d6f350b29765273c00f5/pycm-2.1-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hCollecting livelossplot\n",
            "  Downloading https://files.pythonhosted.org/packages/55/2b/4be0b3de085cfacf25fc1934f391bd85f90565db4f110f3f7b2220666b09/livelossplot-0.4.0-py3-none-any.whl\n",
            "Collecting art>=1.8 (from pycm)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/cb/12329146ae052d8cc797edec123f87ff54f349af34438d01f1ffe7fc6e1c/art-3.6-py2.py3-none-any.whl (489kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 26.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pycm) (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.0.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n",
            "Collecting coverage>=4.1 (from art>=1.8->pycm)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/4e/f28fc04019bac97d301512d904992791569234a06826cd420f78fba9a361/coverage-4.5.3-cp36-cp36m-manylinux1_x86_64.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 33.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.2.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot) (41.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (3.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (17.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.7.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.16)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.7)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement coverage==3.7.1, but you'll have coverage 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: coveralls 0.5 has requirement coverage<3.999,>=3.6, but you'll have coverage 4.5.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: coverage, art, pycm, livelossplot\n",
            "  Found existing installation: coverage 3.7.1\n",
            "    Uninstalling coverage-3.7.1:\n",
            "      Successfully uninstalled coverage-3.7.1\n",
            "Successfully installed art-3.6 coverage-4.5.3 livelossplot-0.4.0 pycm-2.1\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gKjhgzi_qph",
        "colab_type": "text"
      },
      "source": [
        "Module imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAqIjtvZiVfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, RandomCrop, ToPILImage, Pad\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# imports from github\n",
        "from tools import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VOT6jtg_uLq",
        "colab_type": "text"
      },
      "source": [
        "Check runtime device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY6dnhJut2N1",
        "colab_type": "code",
        "outputId": "ef17b501-efa9-437c-99ed-6f4e21f32109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check running device\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPFXq2gJkeTr",
        "colab_type": "text"
      },
      "source": [
        "Mount google drive if wanted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKYmq0jKkiHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "b214fb47-738a-4956-8d9a-b4eddabfaba9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbfBvaS9lQwP",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbKRK5YNidaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_feat = np.load(\"/content/data/kmnist-train-imgs.npy\")\n",
        "train_targ = np.load(\"/content/data/kmnist-train-labels.npy\")\n",
        "test_feat = np.load(\"/content/data/kmnist-test-imgs.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQSmqZ4oLdT",
        "colab_type": "code",
        "outputId": "e79f92a7-26f6-4ed5-cbda-6d9b6300aad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# check what the data looks like\n",
        "for data, data_name in zip([train_targ, test_feat, train_feat], \n",
        "                           [\"train_targ\", \"test_feat\", \"train_feat\"]):\n",
        "    \n",
        "    print(data_name)\n",
        "    \n",
        "    for name, code in zip([\"shape\", \"mean\", \"std\", \"max\", \"min\", \"type\", \"cuda\"],\n",
        "                          [\"data.shape\", \"data.mean()\", \"data.std()\", \n",
        "                           \"data.max()\", \"data.min()\", \"data.dtype\"]):\n",
        "        try:\n",
        "            exec(\"print('\\t', name, '\\t:\\t', \" + code + \")\")\n",
        "        except:\n",
        "            print(\"\\t\", name, \"\\t:\\t undefined\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_targ\n",
            "\t shape \t:\t (60000,)\n",
            "\t mean \t:\t 4.5\n",
            "\t std \t:\t 2.8722813232690143\n",
            "\t max \t:\t 9\n",
            "\t min \t:\t 0\n",
            "\t type \t:\t uint8\n",
            "test_feat\n",
            "\t shape \t:\t (10000, 28, 28)\n",
            "\t mean \t:\t 47.06204145408163\n",
            "\t std \t:\t 87.1110021912918\n",
            "\t max \t:\t 255\n",
            "\t min \t:\t 0\n",
            "\t type \t:\t uint8\n",
            "train_feat\n",
            "\t shape \t:\t (60000, 28, 28)\n",
            "\t mean \t:\t 48.89934757653061\n",
            "\t std \t:\t 88.82742173832395\n",
            "\t max \t:\t 255\n",
            "\t min \t:\t 0\n",
            "\t type \t:\t uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bJ96jN0_KMk",
        "colab_type": "text"
      },
      "source": [
        "Now set our parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo-vgjQzIIEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other Hyperparameters\n",
        "Seed = 42\n",
        "Learning_Rate = 1e-2\n",
        "Momentum = 0.5\n",
        "Batch_Size = 64\n",
        "Test_Batch_Size = 1000\n",
        "Number_of_Epochs = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A76HVstl8Rdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AlexNet_half (Dropout)\n",
        "class AlexNet_half_drop_batch(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural Network inspired on Alexnet, with a reduced number of parameters (989410).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, bias=True):\n",
        "        \"setup the neural network\"\n",
        "        \n",
        "        # initalise\n",
        "        super(AlexNet_half_drop_batch, self).__init__()\n",
        "\n",
        "        # create the activation function\n",
        "        act = nn.ReLU()\n",
        "        \n",
        "        self.convolutional = nn.Sequential(\n",
        "            nn.Conv2d(1, 24, padding=1, kernel_size=4, stride=1, bias=bias), act,\n",
        "            nn.BatchNorm2d(24),\n",
        "            nn.MaxPool2d(kernel_size=1, stride=1), act,\n",
        "            nn.Conv2d(24, 64, padding=2, kernel_size=5, stride=1, bias=bias), act,\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), act,\n",
        "            nn.Conv2d(64, 96, padding=2, kernel_size=5, stride=1, bias=bias), act,\n",
        "            nn.Conv2d(96, 96, padding=1, kernel_size=3, stride=1, bias=bias), act,\n",
        "            nn.Conv2d(96, 64, padding=1, kernel_size=3, stride=1, bias=bias), act,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), act)\n",
        "        \n",
        "        self.full_connected = nn.Sequential(\n",
        "            nn.Linear(2304, 256, bias=bias), act,\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, 256, bias=bias), act,\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, 10, bias=bias)\n",
        "        )\n",
        "\n",
        "    def flatten(self, T):\n",
        "        \"flatten the image for the fully connected layers\"\n",
        "        return T.view(-1, T.size(1)*T.size(2)*T.size(3))\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"Pass through the neural network\"\n",
        "        x = self.convolutional(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.full_connected(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X4oeAD6suKa",
        "colab_type": "text"
      },
      "source": [
        "## Data pre-processing\n",
        "\n",
        "Define the data set creation function with the transformations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9gJPji_BgTY",
        "colab_type": "code",
        "outputId": "29e44b02-ade7-4537-c23e-e750aeb9313e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# do the split\n",
        "n_folds = 10\n",
        "shuffler =  StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
        "shuffler = shuffler.split(train_feat, train_targ)\n",
        "\n",
        "# get the indices\n",
        "indices = np.array(list(shuffler))\n",
        "print(indices.shape)\n",
        "print([i.shape for i in indices.flatten()])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 2)\n",
            "[(54000,), (6000,), (54000,), (6000,), (54000,), (6000,), (54000,), (6000,), (54000,), (6000,), (54000,), (6000,), (54000,), (6000,), (54000,), (6000,), (54000,), (6000,), (54000,), (6000,)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FbwEr7VBgPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_mod(t_feat, v_feat, t_targ, v_targ):\n",
        "    \n",
        "    # make trgets torch type and shape\n",
        "    t_targ = torch.from_numpy(t_targ)\n",
        "    t_targ = t_targ.long()\n",
        "    v_targ = torch.from_numpy(v_targ)\n",
        "    v_targ = v_targ.long()\n",
        "    # (features are changed in the transofrmations)\n",
        "\n",
        "    # find mean and std\n",
        "    mean, std = np.mean(t_feat)/255., np.std(t_feat)/255.\n",
        "    print(\"avg:\", mean, \"std:\", std)\n",
        "    \n",
        "    # includes data augmentation\n",
        "    train_transform = Compose([\n",
        "        ToPILImage(),\n",
        "        RandomCrop(24),\n",
        "        Pad(2),\n",
        "        RandomRotation(15),\n",
        "        ToTensor(),\n",
        "        Normalize(mean=[mean], std=[std]),\n",
        "        ])\n",
        "\n",
        "    # only want to normalize here\n",
        "    validation_test_transform = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize(mean=[mean], std=[std]),\n",
        "        ])\n",
        "\n",
        "    \n",
        "    # create the custom datasets\n",
        "    train_set = CustomImageTensorDataset(t_feat, t_targ, transform=train_transform)\n",
        "    valid_set = CustomImageTensorDataset(v_feat, v_targ, transform=validation_test_transform)\n",
        "\n",
        "    return train_set, valid_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9apXLivwNTa",
        "colab_type": "text"
      },
      "source": [
        "## Symbol Inflation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QAEAvX8X03S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_inflation(t_feat, t_targ, failed_indices=[], no_increase=10, no_random=1):\n",
        "    # find the features and targets we want to duplicate\n",
        "    \n",
        "    to_dupe = []\n",
        "    \n",
        "    # for every symbol class\n",
        "    for sym, fails in enumerate(failed_indices):\n",
        "      \n",
        "      # adding chance of sampling any number with this value\n",
        "      fails = fails + [-1]*no_random\n",
        "      \n",
        "      dupe = np.random.choice(fails, no_increase)\n",
        "    \n",
        "      # every id with this symbol\n",
        "      all_ids = np.where(t_targ == sym)[0]\n",
        "    \n",
        "      for n, i in enumerate(dupe):\n",
        "        if i == -1:\n",
        "          print(\"flag\")\n",
        "          dupe[n] = np.random.choice(all_ids, 1)\n",
        "            \n",
        "      to_dupe.append(dupe)\n",
        "          \n",
        "    to_dupe = np.array(to_dupe).flatten()\n",
        "    dup_feat = t_feat[to_dupe]\n",
        "    dup_targ = t_targ[to_dupe]\n",
        "    \n",
        "    # add to the data sets\n",
        "    t_feat = np.concatenate([t_feat, dup_feat], axis=0)\n",
        "    t_targ = np.concatenate([t_targ, dup_targ], axis=0)\n",
        "\n",
        "    return t_feat, t_targ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Eo0YnWbYHSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def find_failed_indexs(ypred, yact):\n",
        "  failed = [[],[],[],[],[],[],[],[],[],[]]\n",
        "  for i in range(len(yact)):\n",
        "    if (yact[i]!=ypred[i]):\n",
        "      failed[yact[i]].append(i)\n",
        "  return failed\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKkr9g5ZcU3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test this\n",
        "t_index, v_index = indices[0]\n",
        "t_feat, t_targ = train_feat[t_index], train_targ[t_index]\n",
        "v_feat, v_targ = train_feat[v_index], train_targ[v_index]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQlXSvMyYIaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4c4b9da4-a47c-45b5-e04f-f752d3d1092e"
      },
      "source": [
        "model = torch.load(\"/content/models/AlexNet_DropAugBatch_Fixed/WedMorn_150.pth\")\n",
        "\n",
        "wrapper2 = train_wrapper(model[\"model\"], None, None, None, device=device)\n",
        "wrapper2.transform = model[\"transform\"]\n",
        "\n",
        "\n",
        "ypred = wrapper2.evaluate(t_feat, False)\n",
        "print(ypred.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No transform found, test data must be normalised manually\n",
            "(54000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzzIW0E130ES",
        "colab_type": "text"
      },
      "source": [
        "# Image Inflation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdKbNLsOZleZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "065c7a85-ce56-495e-ef74-ecd6c5a2f9aa"
      },
      "source": [
        "failed = find_failed_indexs(ypred, t_targ)\n",
        "\n",
        "print(failed)\n",
        "\n",
        "print(\"pre-inflation:\", t_feat.shape, t_targ.shape)\n",
        "print(np.unique(t_targ, return_counts=True)[1])\n",
        "\n",
        "t_feat_inflated, t_targ_inflated = image_inflation(t_feat, t_targ, failed_indices=failed, no_increase=60, no_random=0)\n",
        "print(\"post-inflation:\", t_feat_inflated.shape, t_targ_inflated.shape)\n",
        "print(np.unique(t_targ_inflated, return_counts=True)[1])\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6627, 10174, 17300, 45563], [16020, 45000, 46907, 47648, 51826, 52655], [7073, 8939, 31545, 33298, 34033, 41352, 47210, 52358], [35014], [40831], [9293, 15423, 25876, 29972], [49429, 50234], [25404, 47736, 53748], [2415, 17154, 40739, 46624], [987, 11193, 24456, 50962]]\n",
            "pre-inflation: (54000, 28, 28) (54000,)\n",
            "[5400 5400 5400 5400 5400 5400 5400 5400 5400 5400]\n",
            "post-inflation: (54600, 28, 28) (54600,)\n",
            "[5460 5460 5460 5460 5460 5460 5460 5460 5460 5460]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgizY7rV30U4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7a65eb9-5014-4b0c-b782-c52a8c193304"
      },
      "source": [
        "t_set, v_set = create_dataset_mod(t_feat_inflated, v_feat, t_targ_inflated, v_targ)\n",
        "\n",
        "train_loader, validate_loader = [DataLoader(t_set, batch_size=Batch_Size, shuffle=True),\n",
        "                                 DataLoader(v_set, batch_size=Test_Batch_Size, shuffle=False)]\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg: 0.19230837536479792 std: 0.34870195523855524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLi2oP-SbhjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byx-6xUYYk1p",
        "colab_type": "text"
      },
      "source": [
        "## TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMphWh7u30Sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c4659e03-245e-4645-a6c1-8bfbc8b9d8d4"
      },
      "source": [
        "# setup\n",
        "set_seed(Seed)\n",
        "model = AlexNet_half_drop_batch().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=Learning_Rate, momentum=Momentum)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "wrapper = train_wrapper(model, optimizer, train_loader, validate_loader, \n",
        "                        criterion=criterion, device=device)\n",
        "wrapper.num_model_params()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of model Parameters:  989586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "989586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYTkQlzSbm6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrapper.train_model(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOukUTOpbkm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-_HiyVObih2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}